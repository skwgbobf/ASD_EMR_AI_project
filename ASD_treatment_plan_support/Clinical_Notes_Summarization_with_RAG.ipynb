{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bfe5dc",
   "metadata": {},
   "source": [
    "# Summarization of Clinical Notes with GPT-3.5 Turbo + DSM-5 Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "This notebook demonstrates how to use GPT-3.5 Turbo and DSM-5 content to summarize clinical notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Specify the path to your .env file\n",
    "dotenv_path = '/home/skbae/Documents/skbae/f.env'\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80724a9d",
   "metadata": {},
   "source": [
    "## Step 1: Load and Split DSM-5 Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d491193",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load DSM-5 PDFs\n",
    "loaders = [\n",
    "    PyPDFLoader(\"/home/skbae/Documents/skbae/ASD/DSM5.pdf\"),\n",
    "]\n",
    "\n",
    "# Load pages from the PDF\n",
    "pages = []\n",
    "for loader in loaders:\n",
    "    pages.extend(loader.load())\n",
    "\n",
    "# Split text into chunks using a Hugging Face tokenizer\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\n",
    "        \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "    ),\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=32,\n",
    "    strip_whitespace=True,\n",
    ")\n",
    "\n",
    "# Split the DSM-5 content into chunks\n",
    "splits = text_splitter.split_documents(pages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e92010",
   "metadata": {},
   "source": [
    "## Step 2: Create a Vector Store for Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a vector store for retrieval using the DSM-5 splits\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Set up a retriever to search for relevant content\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41bfbf8",
   "metadata": {},
   "source": [
    "## Step 3: Define the RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ce8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Custom prompt template for summarization\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "# Create a prompt template\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Define the RAG chain\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883d371a",
   "metadata": {},
   "source": [
    "## Step 4: Summarize Clinical Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4335c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load clinical notes\n",
    "df_merged = pd.read_csv('./df_merged_summary_Apr03.csv')\n",
    "\n",
    "# Define a function to process and summarize clinical notes\n",
    "def process_text2(text):\n",
    "    response = rag_chain.invoke(f\"Please check the below and summarize clear symptoms of ASD on it:\n",
    "{text}\")\n",
    "    lines = response.split('\\n')\n",
    "    return '\\n'.join(lines)  # Join lines into a single string\n",
    "\n",
    "# Apply summarization to the dataset\n",
    "df_merged['summarized_text_llm2F'] = df_merged['deidentified_text'].apply(process_text2)\n",
    "\n",
    "# Save the summarized data\n",
    "df_merged.to_csv('./df_merged_summary2_LLM_F_Apr012F.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ebd4fe",
   "metadata": {},
   "source": [
    "## Step 5: View Summarized Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display the first few rows of the summarized output\n",
    "df_merged[['deidentified_text', 'summarized_text_llm2F']].head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
